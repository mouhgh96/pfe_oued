{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edf9e0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "import os\n",
    "from threading import Thread\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import re\n",
    "import regex\n",
    "import nltk\n",
    "from french_lefff_lemmatizer.french_lefff_lemmatizer import FrenchLefffLemmatizer\n",
    "from threading import Thread\n",
    "import math\n",
    "import unidecode\n",
    "from params import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from joblib import dump, load\n",
    "import time\n",
    "import numpy as np\n",
    "from oued_timing import Timer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from numba import jit, njit\n",
    "import numba\n",
    "#nltk.downlod('all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bb8b80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73006edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.46 ms, sys: 7.81 ms, total: 13.3 ms\n",
      "Wall time: 10.7 ms\n"
     ]
    }
   ],
   "source": [
    "%time array = np.array(df[\"id\"], dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10585b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " had la class fiha les method ga3 ta3 text preprocessing\n",
    "\"\"\"\n",
    "class Preprocessor:\n",
    "    def __init__(self):\n",
    "        self.lemmatizer = FrenchLefffLemmatizer()\n",
    "        self.french_stopwords = set(stopwords.words('french'))\n",
    "        self.stemmer = nltk.stem.snowball.FrenchStemmer()\n",
    "\n",
    "    def get_int_array(self, str_table):\n",
    "        \"\"\"\n",
    "        @param str_table: str => un tableau d'entier \n",
    "        @return [int]\n",
    "        \"\"\"\n",
    "        ok = False\n",
    "        value = 0\n",
    "        ans = []\n",
    "        for c in str_table:\n",
    "            if not c.isnumeric():\n",
    "                if ok:\n",
    "                    ans.append(value)\n",
    "                    value = 0\n",
    "                ok = False\n",
    "            else:\n",
    "                ok = True\n",
    "                value *= 10\n",
    "                value += int(c)\n",
    "        assert ans\n",
    "        return ans\n",
    "    def get_int_array_min(self, str_table):\n",
    "        return min(self.get_int_array(str_table))\n",
    "    def filter_stopfr(self, text):\n",
    "        return [token for token in text if token not in self.french_stopwords]\n",
    "    def clean_txt(self, text):\n",
    "        text = str(text)\n",
    "        text = text.lower()\n",
    "        text = re.sub(\"\"\"[\\.\\!\\\"\\s\\?\\-\\,\\'@&^$`]+\"\"\", \" \",text)\n",
    "        text = re.sub(\"\"\"(\\W|\\d)+\"\"\", \" \",text)\n",
    "        text = regex.sub(u'[^\\p{Latin}]', u' ', text)\n",
    "        words = self.filtre_stopfr(word_tokenize(text, language=\"french\") )\n",
    "        words = [self.lemmatizer.lemmatize(unidecode.unidecode(w)) for w in words]\n",
    "        words = [w for w in words if 3 < len(w) and len(w) < 13]\n",
    "        #words = [self.stemmer.stem(w) for w in words]\n",
    "        return \" \".join(words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f89b9c28",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (265513264.py, line 54)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_52574/265513264.py\"\u001b[0;36m, line \u001b[0;32m54\u001b[0m\n\u001b[0;31m    to_keep = values  THRESHOLD\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def all(src_file_path, dest_file_path): \n",
    "    df = pd.read_csv(src_file_path); \n",
    "    pre = Preprocessor()\n",
    "    def handle(df, start, end):\n",
    "        print(f\"start {start} {end}\")\n",
    "        end = min(end, df.shape[0])\n",
    "        df.loc[start:end, \"title\"] = df.loc[start:end,\"title\"].apply(pre.clean_txt)\n",
    "        df.loc[start:end, \"description\"] = df.loc[start:end,\"description\"].apply(pre.clean_txt)\n",
    "        print(f\"end {start} {end}\")\n",
    "    \n",
    "    rows = df.shape[0]\n",
    "    step = math.ceil(rows / NBR_THREADS)\n",
    "    threads = []\n",
    "    df[\"root\"] = df[\"categories\"].apply(pre.get_int_array_min)\n",
    "    for i in range(0, rows, step):\n",
    "        threads.append(Thread(target=handle, args=(df, i, min(rows, i + step))))\n",
    "        threads[-1].start()\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "    df[\"title\"] = df[\"title\"].fillna(\" \")\n",
    "    df[\"description\"] = df[\"description\"].fillna(\" \")\n",
    "    df[\"text\"] = df[\"title\"] + \" \" + df[\"description\"]\n",
    "    df[\"text\"] = df[\"text\"].fillna(\" \")\n",
    "    df.to_csv(dest_file_path);\n",
    "\n",
    "def learn_text(serie):\n",
    "    vectorizer = TfidfVectorizer(min_df=0.01)\n",
    "    oued = vectorizer.fit_transform((serie))\n",
    "    return oued\n",
    "\n",
    "def learn_category(df, category):\n",
    "    path = Path(f\"{DATA_FRAMES_DIR}/{category}\")\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    cur = df[df[\"root\"] == category];\n",
    "\n",
    "    df_text = cur[[\"id\", \"title\", \"root\", \"description\", \"status\", \"text\"]]\n",
    "    tfidf_title = learn_text(df_text['title'])\n",
    "    tfidf_description = learn_text(df_text['description'])\n",
    "    tfidf_text = learn_text(df_text['text'])\n",
    "    dump(tfidf_title, path / \"title_model.sav\")\n",
    "    dump(tfidf_description, path / \"description_model.sav\")\n",
    "    dump(tfidf_text, path / \"text_model.sav\")\n",
    "    df_text.to_csv(path / \"text_preprocess.csv\");\n",
    "    print(f\"{category} learned\")\n",
    "\n",
    "\n",
    "def get_roots(df):\n",
    "    return list(map(int, df[\"root\"].unique()))\n",
    "\n",
    "#@njit()\n",
    "def compute_jit(title, description, ids):\n",
    "    values = (title * TITLE_ALPHA) + (description * (1 - TITLE_ALPHA))\n",
    "    to_keep = values > THRESHOLD\n",
    "    values = values[to_keep]\n",
    "    ids = ids[to_keep]\n",
    "    srt = np.argsort(values)[::-1]\n",
    "    values = values[srt]\n",
    "    ids = ids[srt]\n",
    "    return (values, ids)\n",
    "def compute(title, description, ids):\n",
    "    values = (title * TITLE_ALPHA) + (description * (1 - TITLE_ALPHA))\n",
    "    torem = values <= THRESHOLD\n",
    "    values = np.delete(values, torem)\n",
    "    ids = np.delete(ids, torem)\n",
    "    srt = np.argsort(values)[::-1]\n",
    "    values = values[srt]\n",
    "    ids = ids[srt]\n",
    "    return (values, ids)\n",
    "    \n",
    "    \n",
    "\n",
    "def learn(src_db):\n",
    "    df = pd.read_csv(src_db)\n",
    "    df[\"title\"] = df[\"title\"].fillna(\" \")\n",
    "    df[\"description\"] = df[\"description\"].fillna(\" \")\n",
    "    df[\"text\"] = df[\"text\"].fillna(\" \")\n",
    "    folders = get_roots(df)\n",
    "    \n",
    "    for folder in folders:\n",
    "        learn_category(df, folder)\n",
    "        print(f\"{folder} learned\")\n",
    "\n",
    "#all(\"../ann.csv\", \"./result.csv\")\n",
    "\n",
    "#cnt = oued_main.Controller(roots)\n",
    "#ls = cnt.recommend(239, 946056)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "238bdfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoryController:\n",
    "    def __init__(self, df, title, description):\n",
    "        self.description = description[(df[\"status\"] == 1)|(df[\"status\"] == 4)]\n",
    "        self.title = title[(df[\"status\"] == 1)|(df[\"status\"] == 4)]\n",
    "        cur = df[(df[\"status\"] == 1)|(df[\"status\"] == 4)]\n",
    "        cur[\"idx\"] = range(cur.shape[0])\n",
    "        cur = cur[[\"id\", \"idx\"]]\n",
    "        self.ids = cur[\"idx\"]\n",
    "        self.ids.index = cur[\"id\"]\n",
    "        self.tmp = np.array(self.ids.index)\n",
    "\n",
    "    @Timer(name=\"get_score\")\n",
    "    def get_score(self, ann_id: int):\n",
    "        index:int = self.ids.get(ann_id, default=-1)\n",
    "        if index < 0:\n",
    "            return []\n",
    "        \n",
    "        title_values = cosine_similarity(self.title, self.title[index]).flatten()\n",
    "        description_values = cosine_similarity(self.description, self.description[index]).flatten()\n",
    "        ans = compute(title_values, description_values, self.tmp)\n",
    "        return ans\n",
    "        #it= filter(lambda p: p[0] > THRESHOLD, compute(title_values, description_values, self.tmp))\n",
    "        #return sorted(it, key=lambda p: p[0], reverse=True)\n",
    "\n",
    "class Controller:\n",
    "    def __init__(self, roots):\n",
    "        self.roots = roots;\n",
    "        self.M = dict()\n",
    "        for root in self.roots:\n",
    "            path = Path(f\"{DATA_FRAMES_DIR}/{root}\")\n",
    "            df = pd.read_csv(path / \"text_preprocess.csv\")\n",
    "            title = load(path / \"title_model.sav\")\n",
    "            description = load(path / \"description_model.sav\")\n",
    "            self.M[root] = CategoryController(df, title, description)\n",
    "\n",
    "    def recommend(self, root, ann_id):\n",
    "        if root not in self.M:\n",
    "            return []\n",
    "        return self.M[root].get_score(ann_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9e998cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "roots = get_roots(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aee1e838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_52574/2565431058.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cur[\"idx\"] = range(cur.shape[0])\n"
     ]
    }
   ],
   "source": [
    "roots = [239]\n",
    "cnt = Controller(roots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7ac5df15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.0285 seconds\n",
      "CPU times: user 28.3 ms, sys: 290 µs, total: 28.6 ms\n",
      "Wall time: 28.8 ms\n"
     ]
    }
   ],
   "source": [
    "%time ans = cnt.recommend(239, 946056)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9b76814c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20879,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans[0].shape\n",
    "ans[1].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
